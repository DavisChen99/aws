# 如何上传数据到S3服务-命令行CLI

> 之前和大家介绍过web界面上传数据到S3，不过对于用惯了命令行的生信人员显然是无法满足的，所以这里给大家介绍下使用命令行来进行s3的数据传输，以便将命令行写入本地代码实现自动化数据传输。
>
> -- D.C

## 安装本地客户端

- 在上传数据之前，需要在本地服务器/本地电脑安装aws cli工具包：

针对Linix：

```bash
curl "https://d1vvhvl2y92vvt.cloudfront.net/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install
```

针对Mac：

```bash
curl "https://d1vvhvl2y92vvt.cloudfront.net/awscli-exe-macos.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install
```
|安装选项|说明|
|----|----|
|--install-dir 或者 -i|此选项指定要将所有文件复制到的文件夹。此示例将文件安装到名为 /usr/local/aws-cli 的文件夹。您必须具有对 /usr/local 的写入权限才能创建此文件夹。<br>默认值为 /usr/local/aws-cli。|
|--bin-dir 或者 -b|此选项指定将安装文件夹中的主 aws 程序符号链接到指定路径中的 aws2 文件。此示例创建符号链接 /usr/local/bin/aws2。您必须具有对指定文件夹的写入权限。创建指向路径中已经存在的文件夹的符号链接后，无需再将安装目录添加到用户的 $PATH 变量中。<br>默认值为 /usr/local/bin。|

- 确认本地安装成功。

```bash
$ aws2 --version
aws-cli/2.0.0dev0 Python/3.7.3 Linux/4.14.133-113.105.amzn2.x86_64 botocore/2.0.0dev0
```

## 配置本地cli环境

- 接着要配置本地的credentials,有点眼熟吧？没错，这个桥段这篇文章出现过-[如何帮EC2摸到S3上的数据](https://www.bioaws.com/blogs/2020-01-28-ec2-s3-data-exchange/)，总而言之就是让服务器具有合法访问的身份。

```bash
$ aws configure
AWS Access Key ID [****************xxxx]:   # 输入你的AK key
AWS Secret Access Key [****************xxxx]: # 输入你的SK key
Default region name [cn-northwest-1]:  # 宁夏：cn-northwest-1，北京：cn-north-1
Default output format [json]:   # 默认json
```

- 测试下，成功摸到s3的小蛮腰。

```
$aws2 s3 ls
2019-09-04 16:12:22 cloudtrail-awslogs
2019-09-21 21:35:26 config-bucket
2019-12-06 13:12:11 rawdata
2019-09-04 16:27:26 do-not-delete
```

## 使用aws cli

### 接下来就要利用本地的aws cli命令上传数据了。通过`aws2 s3 help` 可以看到s3的命令模块：

|桶命令|说明|
|----|----|
|mb|`aws s3 mb s3://bucket-name` <br>创建存储桶，存储桶名称可以包含小写字母、数字、连字符和点号。存储桶名称只能以字母或数字开头和结尾，连字符或点号后不能跟点号。|
|ls|`aws s3 ls`列出您的存储桶<br>`aws s3 ls s3://bucket-name`列出存储桶下的对象和文件夹|
|rb|`aws s3 rb s3://bucket-name`删除空桶<br>`aws s3 rb s3://bucket-name --force` 删除无版本控制的非空桶和桶内所有内容|

|对象命令|说明|
|----|----|
|cp|`aws s3 cp file.txt s3://my-bucket/`<br>拷贝文件到S3，反之亦然|
|mv|`aws s3 cp file.txt s3://my-bucket/`<br>移动本地文件到S3，反之亦然|
|rm|`aws s3 rm s3://my-bucket/path/MySubdirectory/MyFile3.txt`<br>删除S3上的文件MyFile3.txt|
|sync|`aws s3 sync . s3://my-bucket/path`|
|presign|`aws s3 presign s3://awsexamplebucket/test2.txt --expires-in 604800`<br>为某个对象创建特定时间（秒为单位，604800=1周）有效的http访问链接，以供他人访问，国外随意，国内请先开ICP|

以上命令如cp、mv 或 rm用于目录或文件夹时，可以通过添加 **--recursive** 选项来遍历目录树，包括所有子目录。

```
// 删除s3://my-bucket/path 目录和其下所有内容
$ aws s3 rm s3://my-bucket/path --recursive
```

**[注意]**：如果对象很大，所有涉及向S3 存储桶（s3 cp、s3 mv 和 s3 sync）上传对象的高级命令都会自动执行**分段上传**。使用这些命令时，无法恢复失败的上传。如果分段上传由于超时而失败，或者通过按 Ctrl+C 手动取消，AWS CLI 将会清除创建的所有文件并中止上传。此过程可能耗时数分钟。

如果进程被 kill 命令中断或者由于系统故障而中断，则正在进行的分段上传将保留在 Amazon S3 中，必须在 AWS 管理控制台中手动清除，或者使用 s3api abort-multipart-upload 命令来清除。

### 关于**sync**的用法，这里多说几句，因为将来我们会经常打交道，其应用主要有三类：
1. 本地文件系统到 S3
2. S3 到本地文件系统
3. S3 到 Amazon S3

使用格式：`aws s3 sync <source> <target> [--options]`

```bash
$ aws s3 sync . s3://my-bucket/path #如果path不存在会自动创建
upload: MySubdirectory/MyFile3.txt to s3://my-bucket/path/MySubdirectory/MyFile3.txt
upload: MyFile2.txt to s3://my-bucket/path/MyFile2.txt
upload: MyFile1.txt to s3://my-bucket/path/MyFile1.txt
```

- 通过添加 **--delete** 选项来从目标中删除源中不存在的文件或对象。

```
// 测试1：删除本地的文件MyFile1.txt
$ rm ./MyFile1.txt

// 同步不加 --delete，没变化
$ aws s3 sync . s3://my-bucket/path

// 同步加了--deletion，因为源是本地，目标桶内的文件也被删除
$ aws s3 sync . s3://my-bucket/path --delete
delete: s3://my-bucket/path/MyFile1.txt

// 测试2：删除桶内的文件MyFile3.txt
$ aws s3 rm s3://my-bucket/path/MySubdirectory/MyFile3.txt
delete: s3://my-bucket/path/MySubdirectory/MyFile3.txt

// 同步加--deletion,这时候源是s3，目标是本地，所以本地的文件被删除
$ aws s3 sync s3://my-bucket/path . --delete
delete: MySubdirectory\MyFile3.txt
```

- 通过添加 **--storage-class** 选项来设定上传数据的存储类别，神器！特别适用于我有一堆陈芝麻烂谷子的数据要往云上怼的，直接设定**归档模式**就行了！

```
// 将当前目录文件传送到s3，并以<string> 模式存储，默认是STANDARD标准。
$ aws s3 sync . s3://my-bucket/path --storage-class STANDARD
$ aws s3 sync . s3://my-bucket/path --storage-class STANDARD_IA
$ aws s3 sync . s3://my-bucket/path --storage-class ONE-ZONE_IA
$ aws s3 sync . s3://my-bucket/path --storage-class INTELLIGENT_TIERING
$ aws s3 sync . s3://my-bucket/path --storage-class GLACIER
$ aws s3 sync . s3://my-bucket/path --storage-class DEEP_ARCHIVE
$ aws s3 sync . s3://my-bucket/path --storage-class REDUCED_REDUNDANCY
```

- 有些实操过的同学说了，如果我当前目录下有特定数据不想同步怎么办呢？ 别慌，我们有 **--exclude** 和 **--include**，来筛选要在同步操作期间复制的文件或对象，记住include选项一定是和exclude同时出现的，**按顺序应用**，自己体会下吧。

```
假设当前目录有3个文件:
MyFile1.txt
MyFile2.rtf
MyFile88.txt
'''
$ aws s3 sync . s3://my-bucket/path --exclude "*.txt"
upload: MyFile2.rtf to s3://my-bucket/path/MyFile2.rtf
'''
$ aws s3 sync . s3://my-bucket/path --exclude "*.txt" --include "MyFile*.txt"
upload: MyFile1.txt to s3://my-bucket/path/MyFile1.txt
upload: MyFile88.txt to s3://my-bucket/path/MyFile88.txt
upload: MyFile2.rtf to s3://my-bucket/path/MyFile2.rtf
'''
$ aws s3 sync . s3://my-bucket/path --exclude "*.txt" --include "MyFile*.txt" --exclude "MyFile?.txt"
upload: MyFile2.rtf to s3://my-bucket/path/MyFile2.rtf
upload: MyFile88.txt to s3://my-bucket/path/MyFile88.txt
```

- **进阶**：这两个选项还可以和--delete配合使用：

```
假设本地目录和 s3://my-bucket/path 已经同步，并各自包含3个文件:
MyFile1.txt
MyFile2.rtf
MyFile88.txt
'''
// 删除所有本地的 .txt文件
$ rm *.txt

// 同步删除模式, 但不同步删除符合MyFile?.txt命名的文件MyFile1.txt，所以只删除了MyFile88.txt
$ aws s3 sync . s3://my-bucket/path --delete --exclude "my-bucket/path/MyFile?.txt"
delete: s3://my-bucket/path/MyFile88.txt
'''
// 删除s3上的MyFile2.rtf
$ aws s3 rm s3://my-bucket/path/MyFile2.rtf

// 同步删除模式, 但不删除MyFile2.rtf，所以只是把本地之前被删掉的MyFile1.txt恢复到了本地（因为在上一步桶里的这个文件并没有被删除）
$ aws s3 sync s3://my-bucket/path . --delete --exclude "./MyFile2.rtf"
download: s3://my-bucket/path/MyFile1.txt to MyFile1.txt
'''
// 同步删除模式, 本地的MyFile2.rtf被删除了
$ aws s3 sync s3://my-bucket/path . --delete
delete: MyFile2.rtf

//最后
本地目录：
MyFile1.txt

s3桶：
MyFile1.txt
```

- 通过设置 **--acl** 来设定access control list访问权限，有 _private_、_public-read_ 和 _public-read-write_ 值。

```
$ aws s3 sync . s3://my-bucket/path --acl public-read
```

## 将适合你的cli命令整合到现有代码中。

例如：

```py
os.system("aws s3 sync s3://god/ooxx/fq ./path/fq")
...trim
...map
...gatk
os.system("aws s3 sync ./path/bam s3://god/ooxx/bam --storage-class STANDARD_IA")
```

**s3 SDK** 参考：[点我](https://docs.amazonaws.cn/AmazonS3/latest/dev/UsingAWSSDK.html)

**s3 api** 参考：[点我](https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/API/Welcome.html)

> 心走得快了，世界就慢了。
