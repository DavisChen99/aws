# 一些实用的命令(持续更新)

> 其实都是aws cli里面的内容，aws doc上也都有，整理一些常用的作为备忘。
>
> -- D.C

## 开发工具

- [中国区文档](https://docs.amazonaws.cn/index.html?nc2=h_l2_su)

- [Global 文档](https://docs.aws.amazon.com/)

- AWS 命令行工具 [AWS Command Line Interface](https://docs.aws.amazon.com/zh_cn/cli/index.html)

- [AWS CLI 完整命令参考](https://docs.aws.amazon.com/cli/latest/reference/#available-services)

- [Python SDK boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)

- [AWS Cloud Development Kit (AWS CDK)](https://docs.aws.amazon.com/cdk/latest/guide/work-with.html)

- [AWS CLI 批量计算](https://docs.aws.amazon.com/cli/latest/reference/batch/)

- [画架构图在线工具](https://app.diagrams.net/)

### CloudWatch

获取特定实例的 CPU 利用率 (AWS CLI) : 使用 get-metric-statistics 命令获取指定实例的 CPUUtilization 指标（使用指定周期和时间间隔）


```batch
aws cloudwatch get-metric-statistics --namespace AWS/EC2 --metric-name CPUUtilization  --period 3600 \
--statistics Maximum --dimensions Name=InstanceId,Value=i-1234567890abcdef0 \
--start-time 2020-10-18T23:18:00 --end-time 2020-10-19T23:18:00
```

## s3

### 看看s3上用了多少空间

- To find the canonical user ID using the AWS CLI, 这个在设置桶的ACL权限的时候需要用到，一般要求输入要共享数据的其他用户的aws canonical user ID。

```
aws s3api list-buckets --query Owner.ID --output text
```

- 列出桶的大小和文件数量。

格式：`aws s3api list-objects --bucket BUCKETNAME --output json --query "[sum(Contents[].Size), length(Contents[])]"`

```bash
$ aws s3api list-objects --bucket mytestbucket --output json --query "[sum(Contents[].Size), length(Contents[])]"
[
   201509112, # 桶内文件大小
   8  # 桶内文件数量
]
```

- 列出桶内每个文件大小和总占用

格式：`aws s3 ls --summarize --human-readable --recursive s3://YOUR_BUCKET_NAME`   

```bash
$ aws s3 ls --summarize --human-readable --recursive s3://91package/
2020-02-01 21:03:49    0 Bytes 1
2019-12-06 22:33:16  160.0 MiB AtomSetup-x64.exe
2019-12-06 22:33:43  836.2 MiB Docker Desktop Installer.exe
2019-12-18 23:38:36   87.3 MiB GitHubDesktopSetup.exe

Total Objects: 4
   Total Size: 1.1 GiB
```

- 根据关键字查找桶内文件

```
$ aws s3api list-objects --bucket 桶名 --query "Contents[?contains(Key, '文件名称')]"

$ aws s3 ls s3://xxx --recursive | grep xxx | cut -c 32-
```

- 查找某天修改过的文件

```
$ aws s3api list-objects --bucket <bucket name> --query "Contents[?contains(LastModified) > '2017-08-03')]"
```

- 查找某天到某天时间段内修改过的文件

```
$ aws s3api list-objects --bucket <bucket name> --query "Contents[?LastModified > '2017-08-03T23' && LastModified < '2017-08-03T23:15']"
```

- 查找xxx桶内所有深度归档的名字里有pdf的

```
aws s3api list-objects-v2     --bucket xxx桶     --query "Contents[?StorageClass
=='DEEP_ARCHIVE']" --output text | awk '{print $2}' | grep 'pdf'
```

- 命令行归档命令

方法1 - 用`cp`命令,原地变身为归档类型

`aws s3 cp s3://exampe/ s3://exampe/ --storage-class GLACIER --recursive`

方法2 - 用`mv`命令，转移到专门归档的桶

`aws s3 mv s3://xxx/xxx/ s3://xxx/xxx/ --recursive --storage-class DEEP_ARCHIVE`

Storage Class: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA | INTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE. Defaults to 'STANDARD'

- 取回归档的文件

还原lovevideo桶里的xxx.exe，保留10天。

`aws s3api restore-object --bucket lovevideo --key xxx.exe --restore-request Days=10`

恢复lovevideo桶里的dir1下的example.obj文件到standard（无冗余类），保留25天后删除，原归档文件不变。

`$ aws s3api restore-object --bucket lovevideo --key dir1/example.obj --restore-request '{"Days":25,"GlacierJobParameters":{"Tier":"Standard"}}'`

查看还原状态：

```
$ aws s3api head-object --bucket lovevideo --key xxx.exe
{
    "AcceptRanges": "bytes",
    "Restore": "ongoing-request=\"true\"",
    "LastModified": "2020-05-22T07:08:51+00:00",
    "ContentLength": 167780896,
    "ETag": "\"a65d3003c998dawd8a9d8ae47a9ebc51-21\"",
    "ContentType": "application/x-msdownload",
    "Metadata": {},
    "StorageClass": "DEEP_ARCHIVE"
}
```

还原完成的提示信息：

```
{
    "Restore": "ongoing-request=\"false\", expiry-date=\"Sun, 13 Aug 2017 00:00:00 GMT\"",
    ...
    "StorageClass": "DEEP_ARCHIVE",
    "Metadata": {}
}
```

详细参考 [点我](https://aws.amazon.com/cn/premiumsupport/knowledge-center/restore-s3-object-glacier-storage-class/)


- 批量归档小脚本，使用 `bash test.sh folder1 folder2 folder3 ...`

```bash
#!/bin/bash
for arg in "$@" # 文件夹名
do
        echo $arg
        aws s3 sync /xxx/$arg  s3://xxx/$arg --storage-class DEEP_ARCHIVE
done
```

## ec2

### 查看instance信息

`aws ec2 describe-instances` 输出的内容太多，后面用管道加个`awk`吧。

如：
`aws ec2 describe-instances | awk -F\" '/InstanceId/{print $4}'`

## EKS

### k8s installing

`https://kubernetes.io/docs/tasks/tools/install-kubectl/#before-you-begin`
